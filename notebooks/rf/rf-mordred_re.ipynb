{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cf_bonds(mol):\n",
    "    if mol is None:\n",
    "        return 0\n",
    "    try:\n",
    "        abstract_cf = Chem.MolFromSmarts('C-F')\n",
    "        if abstract_cf is None:\n",
    "            return 0\n",
    "        cf_bonds = mol.GetSubstructMatches(abstract_cf)\n",
    "        return len(cf_bonds)\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "ldtoxdb = pd.read_csv('ldtoxdb-mordred2.csv')\n",
    "pfas8k = pd.read_csv('pfas8k-mordred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:28:12] Explicit valence for atom # 1 Cl, 3, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "# Covert SMILES to RDKit mol objects\n",
    "ldtoxdb['rd_mol'] = ldtoxdb.SMI.apply(Chem.MolFromSmiles)\n",
    "# drop rows with no mol object(non mol object can not be appplied molwt)\n",
    "ldtoxdb = ldtoxdb.dropna(subset=['rd_mol'])\n",
    "# count cf bonds\n",
    "ldtoxdb['n_cf_bonds'] = ldtoxdb.rd_mol.apply(count_cf_bonds)\n",
    "# calculate molecular weight (for coversion to mg/kg)   \n",
    "ldtoxdb['mol_wt'] = ldtoxdb.rd_mol.apply(Descriptors.MolWt)\n",
    "# classify pfas like molecules\n",
    "ldtoxdb['is_pfas_like'] = ldtoxdb['n_cf_bonds'] >= 22\n",
    "\n",
    "pfas8k['mol'] = pfas8k.SMILES.apply(Chem.MolFromSmiles)\n",
    "pfas8k = pfas8k.dropna(subset=['mol'])\n",
    "pfas8k['canon_smi'] = pfas8k['mol'].apply(Chem.MolToSmiles)\n",
    "pfas8k = pfas8k.drop('mol', axis=1)\n",
    "ldtoxdb['is_pfas'] = ldtoxdb.SMI.isin(pfas8k.canon_smi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13329, 490), (8154, 357))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldtoxdb.shape,pfas8k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LD50UnitConverter():\n",
    "    # covert neglogld50 to mg/kg\n",
    "    def convert_to_mgkg(self, neglogld50s, smiles):\n",
    "\n",
    "        for neglogld50, smile in zip(neglogld50s, smiles):\n",
    "            molwt = Descriptors.MolWt(Chem.MolFromSmiles(smile[0]))\n",
    "            yield (10**(-1*neglogld50[0]))*1000*molwt\n",
    "        \n",
    "            \n",
    "\n",
    "    # covert mg/kg to epa classes\n",
    "    def convert_to_epa(self, neglogld50s, smiles):\n",
    "        mgkg = list(self.convert_to_mgkg(neglogld50s=neglogld50s, smiles=smiles))\n",
    "\n",
    "        return pd.cut(mgkg, labels=(0,1,2,3), bins=(-np.inf,50,500,5000, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(dataframe):\n",
    "    # feature extraction\n",
    "    mordred = dataframe.columns[6:-5]\n",
    "    \n",
    "    X = dataframe[mordred] \n",
    "    # target\n",
    "    y = dataframe['NeglogLD50']  \n",
    "    smiles = dataframe['SMI']  \n",
    "    print(f'Data loaded with {X.shape[1]} features and {X.shape[0]} samples')\n",
    "    return X, y, smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators, max_depth, min_samples_split, min_samples_leaf, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.random_state = random_state\n",
    "        self.model = RandomForestRegressor(n_estimators=self.n_estimators, \n",
    "                                            max_depth=self.max_depth, \n",
    "                                            min_samples_split=self.min_samples_split, \n",
    "                                            min_samples_leaf=self.min_samples_leaf,\n",
    "                                            random_state=self.random_state,\n",
    "                                            n_jobs=-1)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        if not os.path.exists('chkpts'):\n",
    "            os.makedirs('chkpts')   \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        y_scaled = self.scaler.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "        self.model.fit(X, y_scaled)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred_scaled = self.model.predict(X)\n",
    "        return self.scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    \n",
    "    def train_and_evaluate(self, X, y, smiles, n_splits=5, converter=None):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        fold_predictions = []\n",
    "        \n",
    "        # training and prediction for each fold\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            smiles_train, smiles_test = smiles.iloc[train_index], smiles.iloc[test_index]\n",
    "            \n",
    "            self.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = self.predict(X_test)\n",
    "            \n",
    "            fn = f'chkpts/estimator_fold_{fold+1}.joblib'\n",
    "            joblib.dump(self.model, fn)\n",
    "            \n",
    "            results = pd.DataFrame({\n",
    "                'fold': fold,\n",
    "                'smiles': smiles_test,\n",
    "                'prediction_neglogld50': y_pred,\n",
    "                'actual_neglogld50': y_test,\n",
    "                'index': test_index\n",
    "            })\n",
    "            \n",
    "            if converter:\n",
    "                results['prediction_mgkg'] = list(converter.convert_to_mgkg(y_pred.reshape(-1, 1), smiles_test.values.reshape(-1, 1)))\n",
    "                results['prediction_epa'] = converter.convert_to_epa(y_pred.reshape(-1, 1), smiles_test.values.reshape(-1, 1))\n",
    "                results['actual_mgkg'] = list(converter.convert_to_mgkg(y_test.values.reshape(-1, 1), smiles_test.values.reshape(-1, 1)))\n",
    "                results['actual_epa'] = converter.convert_to_epa(y_test.values.reshape(-1, 1), smiles_test.values.reshape(-1, 1))\n",
    "            \n",
    "            fold_predictions.append(results)\n",
    "            print(f\"Fold {fold+1} training complete\")\n",
    "            print('-'*10)\n",
    "        \n",
    "        all_predictions = pd.concat(fold_predictions).sort_values('index').reset_index(drop=True)\n",
    "        all_predictions.to_csv('rf_predictions.csv', index=False)\n",
    "        \n",
    "        print(\"Predictions saved to rf_predictions.csv\")\n",
    "        \n",
    "        return all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 479 features and 13329 samples\n",
      "Fold 1 training complete\n",
      "----------\n",
      "Fold 2 training complete\n",
      "----------\n",
      "Fold 3 training complete\n",
      "----------\n",
      "Fold 4 training complete\n",
      "----------\n",
      "Fold 5 training complete\n",
      "----------\n",
      "Predictions saved to rf_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_estimators=4096, max_depth=32, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "X, y, smiles = data_loader(ldtoxdb)\n",
    "converter = LD50UnitConverter()\n",
    "predictions = rf.train_and_evaluate(X, y, smiles, converter=converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(predictions_df):\n",
    "\n",
    "    scores = {}\n",
    "    \n",
    "    # Calculate R2 score\n",
    "    scores['R2'] = r2_score(predictions_df['actual_neglogld50'], predictions_df['prediction_neglogld50'])\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    scores['MAE'] = mean_absolute_error(predictions_df['actual_neglogld50'], predictions_df['prediction_neglogld50'])\n",
    "    \n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    scores['RMSE'] = np.sqrt(mean_squared_error(predictions_df['actual_neglogld50'], predictions_df['prediction_neglogld50']))\n",
    "    \n",
    "    # Calculate EPA classification accuracy if available\n",
    "    if 'actual_epa' in predictions_df.columns and 'prediction_epa' in predictions_df.columns:\n",
    "        scores['EPA_Accuracy'] = (predictions_df['actual_epa'] == predictions_df['prediction_epa']).mean()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.6507597734775254\n",
      "MAE: 0.3705976329989629\n",
      "RMSE: 0.5209214928014738\n",
      "EPA_Accuracy: 0.6539875459524346\n"
     ]
    }
   ],
   "source": [
    "# Calculate scores\n",
    "scores = calculate_scores(predictions)\n",
    "\n",
    "for metric, value in scores.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
